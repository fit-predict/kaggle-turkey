{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bidirectional LSTM 15 hidden units.\n",
    "* Batch Normalitzation.\n",
    "* Data padded at the end of the sequences.\n",
    "* Cross validation 10 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_embedding</th>\n",
       "      <th>end_time_seconds_youtube_clip</th>\n",
       "      <th>is_turkey</th>\n",
       "      <th>start_time_seconds_youtube_clip</th>\n",
       "      <th>vid_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[172, 34, 216, 110, 208, 46, 95, 66, 161, 125...</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>kDCk3hLIVXo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[169, 20, 165, 102, 205, 62, 110, 103, 211, 1...</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>DPcGzqHoo7Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[148, 8, 138, 60, 237, 48, 121, 108, 145, 177...</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>7yM63MTHh5k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[151, 0, 162, 88, 171, 71, 47, 90, 179, 190, ...</td>\n",
       "      <td>520</td>\n",
       "      <td>1</td>\n",
       "      <td>510</td>\n",
       "      <td>luG3RmUAxxM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[162, 17, 187, 111, 211, 105, 92, 67, 203, 15...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PIm3cjxTpOk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     audio_embedding  \\\n",
       "0  [[172, 34, 216, 110, 208, 46, 95, 66, 161, 125...   \n",
       "1  [[169, 20, 165, 102, 205, 62, 110, 103, 211, 1...   \n",
       "2  [[148, 8, 138, 60, 237, 48, 121, 108, 145, 177...   \n",
       "3  [[151, 0, 162, 88, 171, 71, 47, 90, 179, 190, ...   \n",
       "4  [[162, 17, 187, 111, 211, 105, 92, 67, 203, 15...   \n",
       "\n",
       "   end_time_seconds_youtube_clip  is_turkey  start_time_seconds_youtube_clip  \\\n",
       "0                             70          0                               60   \n",
       "1                             40          1                               30   \n",
       "2                            240          1                              230   \n",
       "3                            520          1                              510   \n",
       "4                             10          0                                0   \n",
       "\n",
       "        vid_id  \n",
       "0  kDCk3hLIVXo  \n",
       "1  DPcGzqHoo7Y  \n",
       "2  7yM63MTHh5k  \n",
       "3  luG3RmUAxxM  \n",
       "4  PIm3cjxTpOk  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_json('train.json')\n",
    "df_test = pd.read_json('test.json')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "NxTxD\n",
    "T = 10 #rows, seq. length\n",
    "D = 128 #columns, input dim.\n",
    "N = 1195 (train) #samples\n",
    "k = 2 {0,1} #classes\n",
    "M = ?, LSTM latent dim.\n",
    "'''\n",
    "T = 10\n",
    "D = 128\n",
    "N = None\n",
    "k = 1\n",
    "M = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM, Bidirectional, Input, Dense, Flatten, BatchNormalization\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_input = Input(shape=(T,D,))\n",
    "lstm = Bidirectional(LSTM(M, return_sequences=True))(main_input)\n",
    "flat = Flatten()(lstm)\n",
    "bn = BatchNormalization()(flat)\n",
    "main_output = Dense(1, activation='sigmoid')(bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[main_input], outputs=[main_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 10, 300)           334800    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3000)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 3000)              12000     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 3001      \n",
      "=================================================================\n",
      "Total params: 349,801\n",
      "Trainable params: 343,801\n",
      "Non-trainable params: 6,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train_list = []\n",
    "y_train_list = []\n",
    "for i in range(len(df_train)):\n",
    "    X_train = np.array(df_train.loc[i,'audio_embedding'])\n",
    "    #If the sample doesn't have 10 seconds, we instert zeros at the end of the sequence\n",
    "    X_train = pad_sequences(X_train.T, maxlen=10, padding='post').T\n",
    "    X_train = X_train.reshape(10,128)\n",
    "    X_train_list.append(X_train)\n",
    "    \n",
    "    y_train = np.array(df_train.loc[i,'is_turkey'])\n",
    "    y_train = y_train.reshape(1,)\n",
    "    y_train_list.append(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation with 10 folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1075 samples, validate on 120 samples\n",
      "Epoch 1/20\n",
      "1075/1075 [==============================] - 6s 5ms/step - loss: 0.3695 - acc: 0.8288 - val_loss: 0.1456 - val_acc: 0.9667\n",
      "Epoch 2/20\n",
      "1075/1075 [==============================] - 1s 584us/step - loss: 0.1800 - acc: 0.9340 - val_loss: 0.0921 - val_acc: 0.9667\n",
      "Epoch 3/20\n",
      "1075/1075 [==============================] - 1s 590us/step - loss: 0.1654 - acc: 0.9358 - val_loss: 0.0956 - val_acc: 0.9833\n",
      "Epoch 4/20\n",
      "1075/1075 [==============================] - 1s 578us/step - loss: 0.1395 - acc: 0.9526 - val_loss: 0.1027 - val_acc: 0.9500\n",
      "Epoch 5/20\n",
      "1075/1075 [==============================] - 1s 573us/step - loss: 0.1397 - acc: 0.9498 - val_loss: 0.1470 - val_acc: 0.9417\n",
      "Epoch 6/20\n",
      "1075/1075 [==============================] - 1s 584us/step - loss: 0.1251 - acc: 0.9516 - val_loss: 0.1130 - val_acc: 0.9583\n",
      "Epoch 7/20\n",
      "1075/1075 [==============================] - 1s 596us/step - loss: 0.1195 - acc: 0.9516 - val_loss: 0.3584 - val_acc: 0.8667\n",
      "Epoch 8/20\n",
      "1075/1075 [==============================] - 1s 583us/step - loss: 0.1180 - acc: 0.9544 - val_loss: 0.2241 - val_acc: 0.9250\n",
      "Epoch 9/20\n",
      "1075/1075 [==============================] - 1s 570us/step - loss: 0.1186 - acc: 0.9563 - val_loss: 0.1399 - val_acc: 0.9500\n",
      "Epoch 10/20\n",
      "1075/1075 [==============================] - 1s 584us/step - loss: 0.1084 - acc: 0.9609 - val_loss: 0.1103 - val_acc: 0.9583\n",
      "Epoch 11/20\n",
      "1075/1075 [==============================] - 1s 604us/step - loss: 0.1175 - acc: 0.9591 - val_loss: 0.1423 - val_acc: 0.9583\n",
      "Epoch 12/20\n",
      "1075/1075 [==============================] - 1s 587us/step - loss: 0.1026 - acc: 0.9647 - val_loss: 0.0824 - val_acc: 0.9750\n",
      "Epoch 13/20\n",
      "1075/1075 [==============================] - 1s 579us/step - loss: 0.1014 - acc: 0.9637 - val_loss: 0.1143 - val_acc: 0.9417\n",
      "Epoch 14/20\n",
      "1075/1075 [==============================] - 1s 577us/step - loss: 0.1104 - acc: 0.9591 - val_loss: 0.1068 - val_acc: 0.9667\n",
      "Epoch 15/20\n",
      "1075/1075 [==============================] - 1s 584us/step - loss: 0.0945 - acc: 0.9702 - val_loss: 0.0751 - val_acc: 0.9750\n",
      "Epoch 16/20\n",
      "1075/1075 [==============================] - 1s 591us/step - loss: 0.1071 - acc: 0.9619 - val_loss: 0.0761 - val_acc: 0.9667\n",
      "Epoch 17/20\n",
      "1075/1075 [==============================] - 1s 585us/step - loss: 0.0836 - acc: 0.9693 - val_loss: 0.1556 - val_acc: 0.9417\n",
      "Epoch 18/20\n",
      "1075/1075 [==============================] - 1s 609us/step - loss: 0.0907 - acc: 0.9665 - val_loss: 0.0973 - val_acc: 0.9667\n",
      "Epoch 19/20\n",
      "1075/1075 [==============================] - 1s 602us/step - loss: 0.0861 - acc: 0.9740 - val_loss: 0.1446 - val_acc: 0.9250\n",
      "Epoch 20/20\n",
      "1075/1075 [==============================] - 1s 598us/step - loss: 0.0935 - acc: 0.9749 - val_loss: 0.1820 - val_acc: 0.9250\n",
      "Train on 1075 samples, validate on 120 samples\n",
      "Epoch 1/20\n",
      "1075/1075 [==============================] - 1s 597us/step - loss: 0.0910 - acc: 0.9758 - val_loss: 0.1766 - val_acc: 0.9333\n",
      "Epoch 2/20\n",
      "1075/1075 [==============================] - 1s 593us/step - loss: 0.0853 - acc: 0.9665 - val_loss: 0.1673 - val_acc: 0.9583\n",
      "Epoch 3/20\n",
      "1075/1075 [==============================] - 1s 580us/step - loss: 0.0794 - acc: 0.9665 - val_loss: 0.1659 - val_acc: 0.9500\n",
      "Epoch 4/20\n",
      "1075/1075 [==============================] - 1s 591us/step - loss: 0.0776 - acc: 0.9674 - val_loss: 0.3142 - val_acc: 0.8667\n",
      "Epoch 5/20\n",
      "1075/1075 [==============================] - 1s 588us/step - loss: 0.0852 - acc: 0.9674 - val_loss: 0.2585 - val_acc: 0.9000\n",
      "Epoch 6/20\n",
      "1075/1075 [==============================] - 1s 600us/step - loss: 0.0753 - acc: 0.9730 - val_loss: 0.1697 - val_acc: 0.9583\n",
      "Epoch 7/20\n",
      "1075/1075 [==============================] - 1s 579us/step - loss: 0.0661 - acc: 0.9786 - val_loss: 0.2104 - val_acc: 0.9167\n",
      "Epoch 8/20\n",
      "1075/1075 [==============================] - 1s 597us/step - loss: 0.0598 - acc: 0.9814 - val_loss: 0.2751 - val_acc: 0.9083\n",
      "Epoch 9/20\n",
      "1075/1075 [==============================] - 1s 624us/step - loss: 0.0670 - acc: 0.9749 - val_loss: 0.3711 - val_acc: 0.9167\n",
      "Epoch 10/20\n",
      "1075/1075 [==============================] - 1s 606us/step - loss: 0.0822 - acc: 0.9730 - val_loss: 0.3776 - val_acc: 0.8917\n",
      "Epoch 11/20\n",
      "1075/1075 [==============================] - 1s 606us/step - loss: 0.0685 - acc: 0.9684 - val_loss: 0.4583 - val_acc: 0.8333\n",
      "Epoch 12/20\n",
      "1075/1075 [==============================] - 1s 604us/step - loss: 0.0547 - acc: 0.9823 - val_loss: 0.1878 - val_acc: 0.9167\n",
      "Epoch 13/20\n",
      "1075/1075 [==============================] - 1s 584us/step - loss: 0.0471 - acc: 0.9842 - val_loss: 0.2788 - val_acc: 0.9000\n",
      "Epoch 14/20\n",
      "1075/1075 [==============================] - 1s 609us/step - loss: 0.0598 - acc: 0.9758 - val_loss: 1.2320 - val_acc: 0.7500\n",
      "Epoch 15/20\n",
      "1075/1075 [==============================] - 1s 601us/step - loss: 0.0659 - acc: 0.9730 - val_loss: 0.4416 - val_acc: 0.8917\n",
      "Epoch 16/20\n",
      "1075/1075 [==============================] - 1s 600us/step - loss: 0.0558 - acc: 0.9823 - val_loss: 0.4716 - val_acc: 0.8667\n",
      "Epoch 17/20\n",
      "1075/1075 [==============================] - 1s 610us/step - loss: 0.0741 - acc: 0.9684 - val_loss: 0.3151 - val_acc: 0.9167\n",
      "Epoch 18/20\n",
      "1075/1075 [==============================] - 1s 581us/step - loss: 0.0678 - acc: 0.9786 - val_loss: 0.3151 - val_acc: 0.9167\n",
      "Epoch 19/20\n",
      "1075/1075 [==============================] - 1s 593us/step - loss: 0.0585 - acc: 0.9758 - val_loss: 0.1910 - val_acc: 0.9500\n",
      "Epoch 20/20\n",
      "1075/1075 [==============================] - 1s 584us/step - loss: 0.0623 - acc: 0.9786 - val_loss: 0.3760 - val_acc: 0.8833\n",
      "Train on 1075 samples, validate on 120 samples\n",
      "Epoch 1/20\n",
      "1075/1075 [==============================] - 1s 585us/step - loss: 0.0911 - acc: 0.9647 - val_loss: 0.1300 - val_acc: 0.9167\n",
      "Epoch 2/20\n",
      "1075/1075 [==============================] - 1s 588us/step - loss: 0.0866 - acc: 0.9767 - val_loss: 0.1222 - val_acc: 0.9333\n",
      "Epoch 3/20\n",
      "1075/1075 [==============================] - 1s 588us/step - loss: 0.0824 - acc: 0.9740 - val_loss: 0.1536 - val_acc: 0.9417\n",
      "Epoch 4/20\n",
      "1075/1075 [==============================] - 1s 580us/step - loss: 0.0552 - acc: 0.9833 - val_loss: 0.1077 - val_acc: 0.9500\n",
      "Epoch 5/20\n",
      "1075/1075 [==============================] - 1s 585us/step - loss: 0.0660 - acc: 0.9795 - val_loss: 0.0922 - val_acc: 0.9583\n",
      "Epoch 6/20\n",
      "1075/1075 [==============================] - 1s 597us/step - loss: 0.0759 - acc: 0.9684 - val_loss: 0.1293 - val_acc: 0.9417\n",
      "Epoch 7/20\n",
      "1075/1075 [==============================] - 1s 603us/step - loss: 0.0828 - acc: 0.9758 - val_loss: 0.1084 - val_acc: 0.9500\n",
      "Epoch 8/20\n",
      "1075/1075 [==============================] - 1s 604us/step - loss: 0.0719 - acc: 0.9749 - val_loss: 0.1846 - val_acc: 0.9083\n",
      "Epoch 9/20\n",
      "1075/1075 [==============================] - 1s 584us/step - loss: 0.0821 - acc: 0.9758 - val_loss: 0.1136 - val_acc: 0.9500\n",
      "Epoch 10/20\n",
      "1075/1075 [==============================] - 1s 603us/step - loss: 0.0533 - acc: 0.9814 - val_loss: 0.1084 - val_acc: 0.9500\n",
      "Epoch 11/20\n",
      "1075/1075 [==============================] - 1s 589us/step - loss: 0.0395 - acc: 0.9888 - val_loss: 0.0987 - val_acc: 0.9333\n",
      "Epoch 12/20\n",
      "1075/1075 [==============================] - 1s 609us/step - loss: 0.0616 - acc: 0.9740 - val_loss: 0.3700 - val_acc: 0.8917\n",
      "Epoch 13/20\n",
      "1075/1075 [==============================] - 1s 610us/step - loss: 0.0709 - acc: 0.9767 - val_loss: 0.1466 - val_acc: 0.9417\n",
      "Epoch 14/20\n",
      "1075/1075 [==============================] - 1s 597us/step - loss: 0.0676 - acc: 0.9786 - val_loss: 0.2037 - val_acc: 0.9167\n",
      "Epoch 15/20\n",
      "1075/1075 [==============================] - 1s 612us/step - loss: 0.0627 - acc: 0.9814 - val_loss: 0.1495 - val_acc: 0.9417\n",
      "Epoch 16/20\n",
      "1075/1075 [==============================] - 1s 588us/step - loss: 0.0524 - acc: 0.9805 - val_loss: 0.1089 - val_acc: 0.9750\n",
      "Epoch 17/20\n",
      "1075/1075 [==============================] - 1s 589us/step - loss: 0.0448 - acc: 0.9860 - val_loss: 0.3688 - val_acc: 0.8500\n",
      "Epoch 18/20\n",
      "1075/1075 [==============================] - 1s 584us/step - loss: 0.0492 - acc: 0.9879 - val_loss: 0.1117 - val_acc: 0.9667\n",
      "Epoch 19/20\n",
      "1075/1075 [==============================] - 1s 612us/step - loss: 0.0527 - acc: 0.9823 - val_loss: 0.1577 - val_acc: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "1075/1075 [==============================] - 1s 571us/step - loss: 0.0571 - acc: 0.9851 - val_loss: 0.2282 - val_acc: 0.9333\n",
      "Train on 1075 samples, validate on 120 samples\n",
      "Epoch 1/20\n",
      "1075/1075 [==============================] - 1s 578us/step - loss: 0.0576 - acc: 0.9777 - val_loss: 0.1294 - val_acc: 0.9250\n",
      "Epoch 2/20\n",
      "1075/1075 [==============================] - 1s 566us/step - loss: 0.0882 - acc: 0.9702 - val_loss: 0.0684 - val_acc: 0.9917\n",
      "Epoch 3/20\n",
      "1075/1075 [==============================] - 1s 578us/step - loss: 0.0587 - acc: 0.9702 - val_loss: 0.1382 - val_acc: 0.9583\n",
      "Epoch 4/20\n",
      "1075/1075 [==============================] - 1s 590us/step - loss: 0.0802 - acc: 0.9674 - val_loss: 0.1136 - val_acc: 0.9500\n",
      "Epoch 5/20\n",
      "1075/1075 [==============================] - 1s 591us/step - loss: 0.0646 - acc: 0.9823 - val_loss: 0.3204 - val_acc: 0.8667\n",
      "Epoch 6/20\n",
      "1075/1075 [==============================] - 1s 574us/step - loss: 0.0856 - acc: 0.9758 - val_loss: 0.1721 - val_acc: 0.9167\n",
      "Epoch 7/20\n",
      "1075/1075 [==============================] - 1s 568us/step - loss: 0.0620 - acc: 0.9814 - val_loss: 0.1238 - val_acc: 0.9417\n",
      "Epoch 8/20\n",
      "1075/1075 [==============================] - 1s 570us/step - loss: 0.0554 - acc: 0.9851 - val_loss: 0.1680 - val_acc: 0.9000\n",
      "Epoch 9/20\n",
      "1075/1075 [==============================] - 1s 582us/step - loss: 0.0690 - acc: 0.9786 - val_loss: 0.8205 - val_acc: 0.8083\n",
      "Epoch 10/20\n",
      "1075/1075 [==============================] - 1s 583us/step - loss: 0.0731 - acc: 0.9730 - val_loss: 0.3998 - val_acc: 0.8417\n",
      "Epoch 11/20\n",
      "1075/1075 [==============================] - 1s 592us/step - loss: 0.0688 - acc: 0.9758 - val_loss: 0.5923 - val_acc: 0.7917\n",
      "Epoch 12/20\n",
      "1075/1075 [==============================] - 1s 575us/step - loss: 0.0530 - acc: 0.9860 - val_loss: 0.2300 - val_acc: 0.8917\n",
      "Epoch 13/20\n",
      "1075/1075 [==============================] - 1s 570us/step - loss: 0.0546 - acc: 0.9805 - val_loss: 0.3115 - val_acc: 0.8917\n",
      "Epoch 14/20\n",
      "1075/1075 [==============================] - 1s 577us/step - loss: 0.0600 - acc: 0.9767 - val_loss: 0.2501 - val_acc: 0.9333\n",
      "Epoch 15/20\n",
      "1075/1075 [==============================] - 1s 583us/step - loss: 0.0602 - acc: 0.9786 - val_loss: 0.1155 - val_acc: 0.9500\n",
      "Epoch 16/20\n",
      "1075/1075 [==============================] - 1s 601us/step - loss: 0.0574 - acc: 0.9823 - val_loss: 0.0689 - val_acc: 0.9667\n",
      "Epoch 17/20\n",
      "1075/1075 [==============================] - 1s 578us/step - loss: 0.0573 - acc: 0.9805 - val_loss: 0.1093 - val_acc: 0.9417\n",
      "Epoch 18/20\n",
      "1075/1075 [==============================] - 1s 594us/step - loss: 0.0545 - acc: 0.9823 - val_loss: 0.0887 - val_acc: 0.9583\n",
      "Epoch 19/20\n",
      "1075/1075 [==============================] - 1s 588us/step - loss: 0.0549 - acc: 0.9823 - val_loss: 0.2518 - val_acc: 0.8833\n",
      "Epoch 20/20\n",
      "1075/1075 [==============================] - 1s 579us/step - loss: 0.0631 - acc: 0.9805 - val_loss: 0.1035 - val_acc: 0.9583\n",
      "Train on 1075 samples, validate on 120 samples\n",
      "Epoch 1/20\n",
      "1075/1075 [==============================] - 1s 579us/step - loss: 0.0750 - acc: 0.9795 - val_loss: 0.8653 - val_acc: 0.7667\n",
      "Epoch 2/20\n",
      "1075/1075 [==============================] - 1s 573us/step - loss: 0.0610 - acc: 0.9786 - val_loss: 0.0424 - val_acc: 0.9750\n",
      "Epoch 3/20\n",
      "1075/1075 [==============================] - 1s 580us/step - loss: 0.0473 - acc: 0.9842 - val_loss: 0.0939 - val_acc: 0.9667\n",
      "Epoch 4/20\n",
      "1075/1075 [==============================] - 1s 582us/step - loss: 0.0501 - acc: 0.9823 - val_loss: 0.1213 - val_acc: 0.9583\n",
      "Epoch 5/20\n",
      "1075/1075 [==============================] - 1s 597us/step - loss: 0.0645 - acc: 0.9805 - val_loss: 0.0698 - val_acc: 0.9583\n",
      "Epoch 6/20\n",
      "1075/1075 [==============================] - 1s 574us/step - loss: 0.0588 - acc: 0.9823 - val_loss: 0.0971 - val_acc: 0.9583\n",
      "Epoch 7/20\n",
      "1075/1075 [==============================] - 1s 574us/step - loss: 0.0701 - acc: 0.9786 - val_loss: 0.0550 - val_acc: 0.9750\n",
      "Epoch 8/20\n",
      "1075/1075 [==============================] - 1s 594us/step - loss: 0.0631 - acc: 0.9777 - val_loss: 0.0932 - val_acc: 0.9583\n",
      "Epoch 9/20\n",
      "1075/1075 [==============================] - 1s 588us/step - loss: 0.0510 - acc: 0.9842 - val_loss: 0.3448 - val_acc: 0.8833\n",
      "Epoch 10/20\n",
      "1075/1075 [==============================] - 1s 584us/step - loss: 0.0527 - acc: 0.9814 - val_loss: 0.1138 - val_acc: 0.9583\n",
      "Epoch 11/20\n",
      "1075/1075 [==============================] - 1s 584us/step - loss: 0.0495 - acc: 0.9823 - val_loss: 0.1178 - val_acc: 0.9333\n",
      "Epoch 12/20\n",
      "1075/1075 [==============================] - 1s 578us/step - loss: 0.0660 - acc: 0.9777 - val_loss: 0.5176 - val_acc: 0.8250\n",
      "Epoch 13/20\n",
      "1075/1075 [==============================] - 1s 597us/step - loss: 0.0538 - acc: 0.9777 - val_loss: 0.6262 - val_acc: 0.8750\n",
      "Epoch 14/20\n",
      "1075/1075 [==============================] - 1s 576us/step - loss: 0.0634 - acc: 0.9730 - val_loss: 0.2700 - val_acc: 0.9333\n",
      "Epoch 15/20\n",
      "1075/1075 [==============================] - 1s 585us/step - loss: 0.0464 - acc: 0.9833 - val_loss: 0.4850 - val_acc: 0.8667\n",
      "Epoch 16/20\n",
      "1075/1075 [==============================] - 1s 585us/step - loss: 0.0535 - acc: 0.9740 - val_loss: 0.5356 - val_acc: 0.8417\n",
      "Epoch 17/20\n",
      "1075/1075 [==============================] - 1s 598us/step - loss: 0.0574 - acc: 0.9767 - val_loss: 0.1832 - val_acc: 0.9250\n",
      "Epoch 18/20\n",
      "1075/1075 [==============================] - 1s 580us/step - loss: 0.0418 - acc: 0.9870 - val_loss: 0.8712 - val_acc: 0.7833\n",
      "Epoch 19/20\n",
      "1075/1075 [==============================] - 1s 591us/step - loss: 0.0407 - acc: 0.9842 - val_loss: 0.4778 - val_acc: 0.8750\n",
      "Epoch 20/20\n",
      "1075/1075 [==============================] - 1s 575us/step - loss: 0.0507 - acc: 0.9833 - val_loss: 0.0727 - val_acc: 0.9583\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/20\n",
      "1076/1076 [==============================] - 1s 564us/step - loss: 0.0676 - acc: 0.9786 - val_loss: 0.0576 - val_acc: 0.9748\n",
      "Epoch 2/20\n",
      "1076/1076 [==============================] - 1s 594us/step - loss: 0.0542 - acc: 0.9814 - val_loss: 0.2418 - val_acc: 0.9244\n",
      "Epoch 3/20\n",
      "1076/1076 [==============================] - 1s 576us/step - loss: 0.0722 - acc: 0.9823 - val_loss: 0.0768 - val_acc: 0.9496\n",
      "Epoch 4/20\n",
      "1076/1076 [==============================] - 1s 577us/step - loss: 0.0529 - acc: 0.9851 - val_loss: 0.0781 - val_acc: 0.9664\n",
      "Epoch 5/20\n",
      "1076/1076 [==============================] - 1s 581us/step - loss: 0.0505 - acc: 0.9842 - val_loss: 0.1096 - val_acc: 0.9412\n",
      "Epoch 6/20\n",
      "1076/1076 [==============================] - 1s 589us/step - loss: 0.0517 - acc: 0.9805 - val_loss: 0.0494 - val_acc: 0.9916\n",
      "Epoch 7/20\n",
      "1076/1076 [==============================] - 1s 571us/step - loss: 0.0466 - acc: 0.9851 - val_loss: 0.0718 - val_acc: 0.9748\n",
      "Epoch 8/20\n",
      "1076/1076 [==============================] - 1s 577us/step - loss: 0.0552 - acc: 0.9758 - val_loss: 0.1000 - val_acc: 0.9664\n",
      "Epoch 9/20\n",
      "1076/1076 [==============================] - 1s 582us/step - loss: 0.0462 - acc: 0.9814 - val_loss: 0.2283 - val_acc: 0.9328\n",
      "Epoch 10/20\n",
      "1076/1076 [==============================] - 1s 584us/step - loss: 0.0734 - acc: 0.9684 - val_loss: 0.0916 - val_acc: 0.9580\n",
      "Epoch 11/20\n",
      "1076/1076 [==============================] - 1s 588us/step - loss: 0.0583 - acc: 0.9805 - val_loss: 0.3641 - val_acc: 0.8908\n",
      "Epoch 12/20\n",
      "1076/1076 [==============================] - 1s 580us/step - loss: 0.0526 - acc: 0.9786 - val_loss: 0.2130 - val_acc: 0.9244\n",
      "Epoch 13/20\n",
      "1076/1076 [==============================] - 1s 602us/step - loss: 0.0513 - acc: 0.9833 - val_loss: 0.2219 - val_acc: 0.9328\n",
      "Epoch 14/20\n",
      "1076/1076 [==============================] - 1s 580us/step - loss: 0.0651 - acc: 0.9749 - val_loss: 0.1135 - val_acc: 0.9748\n",
      "Epoch 15/20\n",
      "1076/1076 [==============================] - 1s 591us/step - loss: 0.0418 - acc: 0.9898 - val_loss: 0.1644 - val_acc: 0.9412\n",
      "Epoch 16/20\n",
      "1076/1076 [==============================] - 1s 577us/step - loss: 0.0328 - acc: 0.9926 - val_loss: 0.3103 - val_acc: 0.8992\n",
      "Epoch 17/20\n",
      "1076/1076 [==============================] - 1s 594us/step - loss: 0.0543 - acc: 0.9861 - val_loss: 0.4223 - val_acc: 0.8824\n",
      "Epoch 18/20\n",
      "1076/1076 [==============================] - 1s 583us/step - loss: 0.0397 - acc: 0.9861 - val_loss: 0.1504 - val_acc: 0.9244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "1076/1076 [==============================] - 1s 574us/step - loss: 0.0383 - acc: 0.9898 - val_loss: 0.2766 - val_acc: 0.9076\n",
      "Epoch 20/20\n",
      "1076/1076 [==============================] - 1s 566us/step - loss: 0.0602 - acc: 0.9805 - val_loss: 0.0778 - val_acc: 0.9496\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/20\n",
      "1076/1076 [==============================] - 1s 631us/step - loss: 0.0492 - acc: 0.9833 - val_loss: 0.0212 - val_acc: 0.9916\n",
      "Epoch 2/20\n",
      "1076/1076 [==============================] - 1s 590us/step - loss: 0.0475 - acc: 0.9805 - val_loss: 0.0479 - val_acc: 0.9748\n",
      "Epoch 3/20\n",
      "1076/1076 [==============================] - 1s 598us/step - loss: 0.0489 - acc: 0.9814 - val_loss: 0.0561 - val_acc: 0.9748\n",
      "Epoch 4/20\n",
      "1076/1076 [==============================] - 1s 568us/step - loss: 0.0658 - acc: 0.9749 - val_loss: 0.1223 - val_acc: 0.9832\n",
      "Epoch 5/20\n",
      "1076/1076 [==============================] - 1s 579us/step - loss: 0.0705 - acc: 0.9758 - val_loss: 0.0447 - val_acc: 0.9832\n",
      "Epoch 6/20\n",
      "1076/1076 [==============================] - 1s 577us/step - loss: 0.0479 - acc: 0.9833 - val_loss: 0.0602 - val_acc: 0.9664\n",
      "Epoch 7/20\n",
      "1076/1076 [==============================] - 1s 563us/step - loss: 0.0439 - acc: 0.9907 - val_loss: 0.0355 - val_acc: 0.9748\n",
      "Epoch 8/20\n",
      "1076/1076 [==============================] - 1s 581us/step - loss: 0.0404 - acc: 0.9879 - val_loss: 0.0908 - val_acc: 0.9748\n",
      "Epoch 9/20\n",
      "1076/1076 [==============================] - 1s 587us/step - loss: 0.0785 - acc: 0.9749 - val_loss: 0.1137 - val_acc: 0.9664\n",
      "Epoch 10/20\n",
      "1076/1076 [==============================] - 1s 571us/step - loss: 0.0372 - acc: 0.9879 - val_loss: 0.0685 - val_acc: 0.9832\n",
      "Epoch 11/20\n",
      "1076/1076 [==============================] - 1s 590us/step - loss: 0.0355 - acc: 0.9898 - val_loss: 0.0881 - val_acc: 0.9664\n",
      "Epoch 12/20\n",
      "1076/1076 [==============================] - 1s 572us/step - loss: 0.0476 - acc: 0.9851 - val_loss: 0.0456 - val_acc: 0.9832\n",
      "Epoch 13/20\n",
      "1076/1076 [==============================] - 1s 580us/step - loss: 0.0367 - acc: 0.9888 - val_loss: 0.1132 - val_acc: 0.9832\n",
      "Epoch 14/20\n",
      "1076/1076 [==============================] - 1s 579us/step - loss: 0.0500 - acc: 0.9833 - val_loss: 0.1109 - val_acc: 0.9748\n",
      "Epoch 15/20\n",
      "1076/1076 [==============================] - 1s 578us/step - loss: 0.0366 - acc: 0.9916 - val_loss: 0.0938 - val_acc: 0.9664\n",
      "Epoch 16/20\n",
      "1076/1076 [==============================] - 1s 583us/step - loss: 0.0479 - acc: 0.9851 - val_loss: 0.1585 - val_acc: 0.9580\n",
      "Epoch 17/20\n",
      "1076/1076 [==============================] - 1s 569us/step - loss: 0.0571 - acc: 0.9796 - val_loss: 0.0216 - val_acc: 0.9916\n",
      "Epoch 18/20\n",
      "1076/1076 [==============================] - 1s 579us/step - loss: 0.0500 - acc: 0.9777 - val_loss: 0.1166 - val_acc: 0.9580\n",
      "Epoch 19/20\n",
      "1076/1076 [==============================] - 1s 604us/step - loss: 0.0398 - acc: 0.9861 - val_loss: 0.0392 - val_acc: 0.9916\n",
      "Epoch 20/20\n",
      "1076/1076 [==============================] - 1s 598us/step - loss: 0.0626 - acc: 0.9730 - val_loss: 0.1715 - val_acc: 0.9664\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/20\n",
      "1076/1076 [==============================] - 1s 594us/step - loss: 0.0791 - acc: 0.9796 - val_loss: 0.1115 - val_acc: 0.9580\n",
      "Epoch 2/20\n",
      "1076/1076 [==============================] - 1s 597us/step - loss: 0.0827 - acc: 0.9740 - val_loss: 0.0271 - val_acc: 0.9916\n",
      "Epoch 3/20\n",
      "1076/1076 [==============================] - 1s 599us/step - loss: 0.0548 - acc: 0.9805 - val_loss: 0.0335 - val_acc: 0.9916\n",
      "Epoch 4/20\n",
      "1076/1076 [==============================] - 1s 585us/step - loss: 0.0266 - acc: 0.9916 - val_loss: 0.0917 - val_acc: 0.9580\n",
      "Epoch 5/20\n",
      "1076/1076 [==============================] - 1s 603us/step - loss: 0.0281 - acc: 0.9916 - val_loss: 0.1863 - val_acc: 0.9244\n",
      "Epoch 6/20\n",
      "1076/1076 [==============================] - 1s 594us/step - loss: 0.0349 - acc: 0.9851 - val_loss: 0.2857 - val_acc: 0.9076\n",
      "Epoch 7/20\n",
      "1076/1076 [==============================] - 1s 578us/step - loss: 0.0528 - acc: 0.9758 - val_loss: 0.0695 - val_acc: 0.9580\n",
      "Epoch 8/20\n",
      "1076/1076 [==============================] - 1s 577us/step - loss: 0.0521 - acc: 0.9851 - val_loss: 0.0476 - val_acc: 0.9748\n",
      "Epoch 9/20\n",
      "1076/1076 [==============================] - 1s 571us/step - loss: 0.0283 - acc: 0.9916 - val_loss: 0.0241 - val_acc: 0.9916\n",
      "Epoch 10/20\n",
      "1076/1076 [==============================] - 1s 604us/step - loss: 0.0401 - acc: 0.9870 - val_loss: 0.0335 - val_acc: 0.9832\n",
      "Epoch 11/20\n",
      "1076/1076 [==============================] - 1s 582us/step - loss: 0.0475 - acc: 0.9823 - val_loss: 0.0215 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "1076/1076 [==============================] - 1s 607us/step - loss: 0.0429 - acc: 0.9870 - val_loss: 0.0463 - val_acc: 0.9748\n",
      "Epoch 13/20\n",
      "1076/1076 [==============================] - 1s 602us/step - loss: 0.0474 - acc: 0.9851 - val_loss: 0.1303 - val_acc: 0.9244\n",
      "Epoch 14/20\n",
      "1076/1076 [==============================] - 1s 593us/step - loss: 0.0466 - acc: 0.9833 - val_loss: 0.0780 - val_acc: 0.9748\n",
      "Epoch 15/20\n",
      "1076/1076 [==============================] - 1s 586us/step - loss: 0.0606 - acc: 0.9805 - val_loss: 0.4680 - val_acc: 0.8403\n",
      "Epoch 16/20\n",
      "1076/1076 [==============================] - 1s 632us/step - loss: 0.0436 - acc: 0.9861 - val_loss: 0.0861 - val_acc: 0.9748\n",
      "Epoch 17/20\n",
      "1076/1076 [==============================] - 1s 594us/step - loss: 0.0557 - acc: 0.9814 - val_loss: 0.2690 - val_acc: 0.8655\n",
      "Epoch 18/20\n",
      "1076/1076 [==============================] - 1s 584us/step - loss: 0.0559 - acc: 0.9823 - val_loss: 0.2287 - val_acc: 0.9076\n",
      "Epoch 19/20\n",
      "1076/1076 [==============================] - 1s 579us/step - loss: 0.0626 - acc: 0.9758 - val_loss: 0.2176 - val_acc: 0.9244\n",
      "Epoch 20/20\n",
      "1076/1076 [==============================] - 1s 615us/step - loss: 0.0480 - acc: 0.9833 - val_loss: 0.1988 - val_acc: 0.9076\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/20\n",
      "1076/1076 [==============================] - 1s 602us/step - loss: 0.0421 - acc: 0.9879 - val_loss: 0.0560 - val_acc: 0.9832\n",
      "Epoch 2/20\n",
      "1076/1076 [==============================] - 1s 599us/step - loss: 0.0326 - acc: 0.9907 - val_loss: 0.0542 - val_acc: 0.9832\n",
      "Epoch 3/20\n",
      "1076/1076 [==============================] - 1s 607us/step - loss: 0.0518 - acc: 0.9796 - val_loss: 0.1488 - val_acc: 0.9496\n",
      "Epoch 4/20\n",
      "1076/1076 [==============================] - 1s 618us/step - loss: 0.0736 - acc: 0.9796 - val_loss: 0.0478 - val_acc: 0.9748\n",
      "Epoch 5/20\n",
      "1076/1076 [==============================] - 1s 603us/step - loss: 0.0564 - acc: 0.9842 - val_loss: 0.0592 - val_acc: 0.9664\n",
      "Epoch 6/20\n",
      "1076/1076 [==============================] - 1s 601us/step - loss: 0.0590 - acc: 0.9749 - val_loss: 0.2014 - val_acc: 0.9496\n",
      "Epoch 7/20\n",
      "1076/1076 [==============================] - 1s 601us/step - loss: 0.0462 - acc: 0.9851 - val_loss: 0.2047 - val_acc: 0.9496\n",
      "Epoch 8/20\n",
      "1076/1076 [==============================] - 1s 593us/step - loss: 0.0491 - acc: 0.9814 - val_loss: 0.2130 - val_acc: 0.9496\n",
      "Epoch 9/20\n",
      "1076/1076 [==============================] - 1s 628us/step - loss: 0.0397 - acc: 0.9861 - val_loss: 0.1002 - val_acc: 0.9748\n",
      "Epoch 10/20\n",
      "1076/1076 [==============================] - 1s 594us/step - loss: 0.0473 - acc: 0.9842 - val_loss: 0.1824 - val_acc: 0.9412\n",
      "Epoch 11/20\n",
      "1076/1076 [==============================] - 1s 583us/step - loss: 0.0456 - acc: 0.9870 - val_loss: 0.3071 - val_acc: 0.9244\n",
      "Epoch 12/20\n",
      "1076/1076 [==============================] - 1s 608us/step - loss: 0.0593 - acc: 0.9833 - val_loss: 0.0439 - val_acc: 0.9832\n",
      "Epoch 13/20\n",
      "1076/1076 [==============================] - 1s 598us/step - loss: 0.0484 - acc: 0.9842 - val_loss: 0.1027 - val_acc: 0.9748\n",
      "Epoch 14/20\n",
      "1076/1076 [==============================] - 1s 616us/step - loss: 0.0468 - acc: 0.9814 - val_loss: 0.0919 - val_acc: 0.9832\n",
      "Epoch 15/20\n",
      "1076/1076 [==============================] - 1s 591us/step - loss: 0.0526 - acc: 0.9796 - val_loss: 0.1089 - val_acc: 0.9748\n",
      "Epoch 16/20\n",
      "1076/1076 [==============================] - 1s 597us/step - loss: 0.0470 - acc: 0.9861 - val_loss: 0.3591 - val_acc: 0.8992\n",
      "Epoch 17/20\n",
      "1076/1076 [==============================] - 1s 609us/step - loss: 0.0390 - acc: 0.9823 - val_loss: 0.3015 - val_acc: 0.8992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "1076/1076 [==============================] - 1s 612us/step - loss: 0.0614 - acc: 0.9768 - val_loss: 0.0271 - val_acc: 0.9832\n",
      "Epoch 19/20\n",
      "1076/1076 [==============================] - 1s 613us/step - loss: 0.0368 - acc: 0.9851 - val_loss: 0.0495 - val_acc: 0.9832\n",
      "Epoch 20/20\n",
      "1076/1076 [==============================] - 1s 598us/step - loss: 0.0393 - acc: 0.9861 - val_loss: 0.0986 - val_acc: 0.9832\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/20\n",
      "1076/1076 [==============================] - 1s 582us/step - loss: 0.0502 - acc: 0.9805 - val_loss: 0.0332 - val_acc: 0.9832\n",
      "Epoch 2/20\n",
      "1076/1076 [==============================] - 1s 603us/step - loss: 0.0446 - acc: 0.9842 - val_loss: 0.0440 - val_acc: 0.9916\n",
      "Epoch 3/20\n",
      "1076/1076 [==============================] - 1s 617us/step - loss: 0.0373 - acc: 0.9888 - val_loss: 0.0579 - val_acc: 0.9580\n",
      "Epoch 4/20\n",
      "1076/1076 [==============================] - 1s 599us/step - loss: 0.0345 - acc: 0.9907 - val_loss: 0.0730 - val_acc: 0.9748\n",
      "Epoch 5/20\n",
      "1076/1076 [==============================] - 1s 591us/step - loss: 0.0665 - acc: 0.9823 - val_loss: 0.0650 - val_acc: 0.9832\n",
      "Epoch 6/20\n",
      "1076/1076 [==============================] - 1s 599us/step - loss: 0.0463 - acc: 0.9786 - val_loss: 0.1969 - val_acc: 0.9244\n",
      "Epoch 7/20\n",
      "1076/1076 [==============================] - 1s 608us/step - loss: 0.0514 - acc: 0.9768 - val_loss: 0.2018 - val_acc: 0.9244\n",
      "Epoch 8/20\n",
      "1076/1076 [==============================] - 1s 591us/step - loss: 0.0371 - acc: 0.9898 - val_loss: 0.0308 - val_acc: 0.9916\n",
      "Epoch 9/20\n",
      "1076/1076 [==============================] - 1s 604us/step - loss: 0.0379 - acc: 0.9814 - val_loss: 0.1133 - val_acc: 0.9412\n",
      "Epoch 10/20\n",
      "1076/1076 [==============================] - 1s 595us/step - loss: 0.0326 - acc: 0.9907 - val_loss: 0.1328 - val_acc: 0.9580\n",
      "Epoch 11/20\n",
      "1076/1076 [==============================] - 1s 594us/step - loss: 0.0346 - acc: 0.9879 - val_loss: 0.0548 - val_acc: 0.9832\n",
      "Epoch 12/20\n",
      "1076/1076 [==============================] - 1s 607us/step - loss: 0.0582 - acc: 0.9786 - val_loss: 0.0950 - val_acc: 0.9664\n",
      "Epoch 13/20\n",
      "1076/1076 [==============================] - 1s 577us/step - loss: 0.0497 - acc: 0.9879 - val_loss: 0.0222 - val_acc: 0.9916\n",
      "Epoch 14/20\n",
      "1076/1076 [==============================] - 1s 599us/step - loss: 0.0387 - acc: 0.9898 - val_loss: 0.0440 - val_acc: 0.9832\n",
      "Epoch 15/20\n",
      "1076/1076 [==============================] - 1s 598us/step - loss: 0.0436 - acc: 0.9851 - val_loss: 0.0332 - val_acc: 0.9832\n",
      "Epoch 16/20\n",
      "1076/1076 [==============================] - 1s 602us/step - loss: 0.0236 - acc: 0.9944 - val_loss: 0.0500 - val_acc: 0.9748\n",
      "Epoch 17/20\n",
      "1076/1076 [==============================] - 1s 588us/step - loss: 0.0430 - acc: 0.9823 - val_loss: 0.0868 - val_acc: 0.9664\n",
      "Epoch 18/20\n",
      "1076/1076 [==============================] - 1s 594us/step - loss: 0.0609 - acc: 0.9777 - val_loss: 0.0521 - val_acc: 0.9832\n",
      "Epoch 19/20\n",
      "1076/1076 [==============================] - 1s 621us/step - loss: 0.0582 - acc: 0.9805 - val_loss: 0.1045 - val_acc: 0.9328\n",
      "Epoch 20/20\n",
      "1076/1076 [==============================] - 1s 602us/step - loss: 0.0404 - acc: 0.9898 - val_loss: 0.0199 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "X_train_list = np.array(X_train_list)\n",
    "y_train_list = np.array(y_train_list)\n",
    "\n",
    "for train_index, test_index in kf.split(X_train_list):\n",
    "    Xtrain = X_train_list[train_index]\n",
    "    Xtest = X_train_list[test_index]\n",
    "    ytrain = y_train_list[train_index]\n",
    "    ytest = y_train_list[test_index]\n",
    "    \n",
    "    model.fit(np.array(Xtrain), np.array(ytrain), epochs=10, batch_size=128, validation_data=(Xtest, ytest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_embedding</th>\n",
       "      <th>end_time_seconds_youtube_clip</th>\n",
       "      <th>start_time_seconds_youtube_clip</th>\n",
       "      <th>vid_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[177, 20, 226, 132, 198, 81, 111, 59, 132, 18...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>pyKh38FXD3E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[169, 21, 204, 161, 195, 72, 60, 39, 152, 184...</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>THhP1idrWXA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[165, 13, 198, 141, 199, 81, 173, 54, 119, 11...</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>jsw3T6GY2Nw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[167, 18, 188, 159, 198, 63, 156, 36, 179, 22...</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>nFkXTMHcjMU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[178, 32, 181, 100, 198, 46, 82, 83, 136, 227...</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>Au8g9kAlrLQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     audio_embedding  \\\n",
       "0  [[177, 20, 226, 132, 198, 81, 111, 59, 132, 18...   \n",
       "1  [[169, 21, 204, 161, 195, 72, 60, 39, 152, 184...   \n",
       "2  [[165, 13, 198, 141, 199, 81, 173, 54, 119, 11...   \n",
       "3  [[167, 18, 188, 159, 198, 63, 156, 36, 179, 22...   \n",
       "4  [[178, 32, 181, 100, 198, 46, 82, 83, 136, 227...   \n",
       "\n",
       "   end_time_seconds_youtube_clip  start_time_seconds_youtube_clip       vid_id  \n",
       "0                             10                                0  pyKh38FXD3E  \n",
       "1                             40                               30  THhP1idrWXA  \n",
       "2                             40                               30  jsw3T6GY2Nw  \n",
       "3                             24                               14  nFkXTMHcjMU  \n",
       "4                             40                               30  Au8g9kAlrLQ  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding the new data like we did during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "for i in range(len(df_test)):\n",
    "    pred = np.array(df_test.loc[i,'audio_embedding'])\n",
    "    pred = pad_sequences(pred.T, maxlen=10, padding='post').T\n",
    "    pred = pred.reshape(10,128)\n",
    "    pred_list.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(np.array(pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['is_turkey'] = preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[['vid_id', 'is_turkey']].to_csv('my_dinner.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
